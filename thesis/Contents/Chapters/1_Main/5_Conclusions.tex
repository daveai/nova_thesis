\chapter{Conclusion}

\section{Summary of Findings}

This thesis compared econometric and machine learning approaches to volatility forecasting across cryptocurrency and traditional assets, using daily data from 2019 to 2025 and Diebold-Mariano tests to distinguish real performance differences from noise. The results do not support any single model as universally better.

For the S\&P 500, the headline result is negative: no machine learning method significantly improves on GARCH. LSTM performs worse than GARCH outright. Only EGARCH, which captures the leverage effect directly, achieves a statistically significant improvement (p<0.01). In mature equity markets, model structure matters more than model complexity.

For Bitcoin, all machine learning methods significantly outperform GARCH(1,1), with XGBoost achieving the lowest RMSE (0.1848), Random Forest close behind (0.1855), and LSTM further at 0.1943. The improvement of approximately 11 per cent relative to GARCH is statistically significant. For practitioners concerned with Bitcoin volatility, these findings suggest that machine learning approaches offer measurable benefits.

These findings do not generalise within the cryptocurrency asset class. For Ethereum, no machine learning method significantly improves upon GARCH, and EGARCH achieves the lowest errors. The divergence between Bitcoin and Ethereum results (machine learning methods significantly improving forecasts for one cryptocurrency but not the other) constitutes one of the more striking findings of this study.

Model selection, these findings suggest, needs to proceed at the level of individual assets rather than asset categories. The temptation to generalise from one cryptocurrency to another, or to assume that methods ineffective for one asset will prove similarly ineffective for others, is not supported by the evidence presented here.

\section{Contributions}

This thesis makes several contributions to the volatility forecasting literature:

\begin{enumerate}
    \item \textbf{Cross-asset comparison with consistent methodology}. By applying identical methods across both cryptocurrency and traditional assets, the analysis permits direct comparison where most existing studies focus on one domain or the other. This design controls for methodological differences that complicate interpretation of findings across studies.

    \item \textbf{Documentation of within-class variation}. The finding that machine learning methods significantly improve Bitcoin forecasts but not Ethereum forecasts challenges categorical assumptions about cryptocurrency volatility modelling. Performance appears to depend on asset-specific characteristics that do not align neatly with asset-class boundaries.

    \item \textbf{Evidence that model structure outperforms model complexity for equities}. For the S\&P 500, EGARCH is the only method to significantly outperform GARCH. Machine learning methods, including LSTM, do not add value over the asymmetric econometric specification. The leverage effect appears to be the dominant feature of equity volatility, and EGARCH captures it directly.

    \item \textbf{Reproducible analysis}. The analysis employs fixed random seeds and documented procedures, permitting replication and extension.
\end{enumerate}

\section{Limitations}

The main limitations on interpretation are:

\begin{enumerate}
    \item \textbf{LSTM architecture}. The neural network specification employed (two layers of 64 and 32 units with 30-day lookback) represents one of many possible configurations. Attention mechanisms, Transformer architectures, or alternative hyperparameter selections might yield different results. Whether architectural modifications would alter the Bitcoin-Ethereum divergence remains an open question.

    \item \textbf{Training asymmetry}. GARCH models were re-estimated at each forecasting step, whilst machine learning models were trained once on the initial training set. This approach reflects typical deployment practice but gives econometric methods more capacity to adapt to recent market developments.

    \item \textbf{Forecast horizon}. The analysis focuses exclusively on 5-day ahead volatility forecasts. Different horizons (shorter or longer) might favour different models. LSTM's capacity to capture extended temporal dependencies might prove more advantageous at longer forecast horizons.

    \item \textbf{Feature specification}. Machine learning models employed only price-based features: lagged returns and realised volatility measures. Alternative feature sets (incorporating sentiment indicators, on-chain metrics for cryptocurrencies, or options-implied volatility) might improve machine learning performance.

    \item \textbf{Sample period}. The 2019--2025 period includes several unusual market episodes, including the COVID-19 market disruption and multiple cryptocurrency boom-bust cycles. Whether the findings generalise to other sample periods remains uncertain.
\end{enumerate}

\section{Implications for Practice}

A few points for practitioners:

\begin{enumerate}
    \item \textbf{Asset-specific validation}. The divergence between Bitcoin and Ethereum results demonstrates that performance for one asset does not predict performance for another, even within the same asset class. Model selection should proceed through testing on each asset of interest rather than reliance on categorical assumptions.

    \item \textbf{Statistical significance testing}. Some apparent improvements in RMSE do not achieve statistical significance under formal testing. Adopting methods based solely on point estimates risks implementing approaches that offer no genuine advantage.

    \item \textbf{For equity markets, use EGARCH not LSTM}. EGARCH is the only method to significantly outperform GARCH for the S\&P 500. LSTM performs worse than GARCH outright. The computational investment in neural network implementation is not supported by the evidence for this asset class.

    \item \textbf{LSTM is worth testing for crypto, but validate per asset}. LSTM significantly outperforms GARCH for Bitcoin, but not for Ethereum. Deployment decisions should be based on per-asset validation, not on categorical assumptions.
\end{enumerate}

\section{Directions for Future Research}

The clearest next step is testing more sophisticated neural network architectures. Transformers and attention mechanisms have shown strong results in sequence modelling elsewhere, and whether they improve on LSTM for assets where it currently falls short is a natural empirical question. Periodic retraining of machine learning models would also address the training asymmetry described above: updating models monthly or quarterly would allow fairer comparison with rolling GARCH estimation, at the cost of considerable computation. Intraday data might favour sequence models more consistently than daily frequency does, since the temporal structure available to the models would be richer. Hybrid approaches, such as using GARCH forecasts as features for machine learning models or feeding GARCH residuals into an LSTM, represent another avenue with some theoretical appeal. The most practically valuable extension, though, would translate the statistical improvements found here into economic terms: actual trading performance, option pricing accuracy, or risk management outcomes. That is ultimately what motivates volatility forecasting.

\section{Concluding Remarks}

Machine learning does not straightforwardly beat econometric methods for volatility forecasting. For Bitcoin, all machine learning methods significantly outperform GARCH. For the S\&P 500, none of them do, and LSTM is the worst-performing model. For Ethereum, the picture is similarly mixed. The findings point in different directions depending on the asset.

These findings suggest that volatility dynamics are more heterogeneous than is often assumed. Different assets, driven by different market participants operating with different information and objectives, appear to require different modelling approaches. The search for a single optimal method is probably less productive than developing asset-specific approaches, selected through rigorous out-of-sample testing with appropriate statistical validation.

What works depends on the specific dynamics of each asset. The most reliable path to model selection remains empirical evaluation, with careful attention to statistical significance, conducted on an asset-by-asset basis.
