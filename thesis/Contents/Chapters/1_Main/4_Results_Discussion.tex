\chapter{Results and Discussion}

The results do not fit a simple ``ML beats GARCH'' narrative.

\section{Forecasting Performance}

Table \ref{tab:main_results} reports the out-of-sample root mean squared error (RMSE) for each model-asset combination. RMSE is the primary metric because it penalises large errors heavily, which matters when the concern is missing a volatility spike.

\begin{table}[htbp]
\centering
\caption{Out-of-Sample Forecasting Performance (RMSE)}
\label{tab:main_results}
\begin{tabular}{lccccc}
\toprule
Asset & GARCH(1,1) & EGARCH & Random Forest & XGBoost & LSTM \\
\midrule
BTC & 0.2076 & 0.2097 & 0.1855 & \textbf{0.1848} & 0.1943 \\
ETH & 0.3032 & \textbf{0.2979} & 0.3128 & 0.3291 & 0.3007 \\
SPX & 0.1392 & 0.1294 & 0.1362 & \textbf{0.1286} & 0.1430 \\
VIX$^\dagger$ & 0.9758 & 0.9222 & \textbf{0.7916} & 0.8662 & 0.9174 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Note: Bold indicates lowest RMSE for each asset.
\item $^\dagger$ VIX results require separate interpretation; see Section 4.5.
\item RMSE expressed in annualised volatility (decimal form). A value of 0.10 corresponds to 10 percentage points.
\end{tablenotes}
\end{table}

For Bitcoin, tree-based methods perform best, with XGBoost achieving an RMSE of 0.1848; all three machine learning methods significantly outperform GARCH. For Ethereum, EGARCH achieves the strongest performance while machine learning methods offer no significant improvement. For the S\&P 500, XGBoost achieves the lowest raw RMSE (0.1286), though the Diebold-Mariano test does not confirm this as significant; EGARCH is the only method to significantly outperform GARCH for equities. LSTM performs worse than GARCH outright for SPX. The VIX results favour Random Forest.

From a practical standpoint, the Bitcoin improvement is the most actionable: an 11 per cent RMSE reduction from machine learning, confirmed as statistically significant, could meaningfully affect risk management decisions.

\subsection{Statistical Significance: Diebold-Mariano Tests}

Point estimates of forecast accuracy, while informative, do not establish whether observed differences reflect genuine performance disparities or sampling variation. The Diebold-Mariano test addresses this directly. Table \ref{tab:dm_test} summarises the results, comparing each model against GARCH(1,1) as the benchmark.

\begin{table}[htbp]
\centering
\caption{Diebold-Mariano Test Results}
\label{tab:dm_test}
\begin{tabular}{lcccc}
\toprule
Comparison & BTC & ETH & SPX & VIX \\
\midrule
RF vs GARCH & *** & ns & ns & *** \\
XGBoost vs GARCH & *** & ns & ns & ** \\
EGARCH vs GARCH & * & ** & *** & *** \\
LSTM vs GARCH & ** & ns & ns & ns \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item *** p<0.01, ** p<0.05, * p<0.10, ns = not significant.
\item Negative statistic indicates first model outperforms benchmark (lower squared errors than GARCH).
\end{tablenotes}
\end{table}

The formal tests mostly confirm the rankings, but with some important qualifications:

\begin{itemize}
    \item \textbf{Bitcoin}: All machine learning methods achieve statistically significant improvements over GARCH(1,1). XGBoost and RF are significant at the 1 per cent level; LSTM at the 5 per cent level. XGBoost achieves the lowest RMSE. EGARCH, by contrast, performs marginally worse than the symmetric baseline (DM=+1.65, p=0.10), with GARCH outperforming EGARCH for this asset. These results suggest that machine learning approaches capture patterns in Bitcoin volatility that GARCH misses, while asymmetric volatility specifications offer no advantage here.

    \item \textbf{Ethereum}: Neither the tree-based methods nor LSTM demonstrates statistically significant improvement over GARCH. EGARCH, however, achieves a significant improvement over the symmetric specification (p<0.05), consistent with the presence of asymmetric volatility dynamics.

    \item \textbf{S\&P 500}: EGARCH achieves statistically significant improvement over GARCH(1,1) at the 1 per cent level. No machine learning method significantly outperforms GARCH, and LSTM produces higher forecast errors than the GARCH baseline. The asymmetric specification's ability to capture the leverage effect appears to be the dominant feature of equity volatility that symmetric GARCH misses.

    \item \textbf{VIX}: Random Forest and XGBoost both significantly outperform GARCH, as does EGARCH. The LSTM shows no significant difference from GARCH. As discussed in Section 4.5, these results require careful interpretation.
\end{itemize}

\subsection{Cryptocurrency Assets}

The Bitcoin results present a consistent picture favouring machine learning methods. XGBoost achieves the lowest RMSE (0.1848), with Random Forest close behind (0.1855) and LSTM further at 0.1943. The Diebold-Mariano tests confirm that all three machine learning methods significantly outperform GARCH(1,1): XGBoost and RF at the 1 per cent level, LSTM at the 5 per cent level. The improvement of approximately 11 per cent relative to GARCH suggests that machine learning approaches capture patterns in Bitcoin volatility that traditional econometric methods do not.

The Ethereum results are a different story. EGARCH achieves the lowest RMSE (0.2979), whilst machine learning methods offer no significant improvement over the GARCH baseline. The tree-based methods and LSTM all produce higher forecast errors than the asymmetric econometric specification.

This divergence within the same asset class raises questions about the transferability of modelling approaches. Bitcoin and Ethereum share certain structural characteristics: both trade continuously, both exhibit high volatility relative to traditional assets, and both attract broadly similar investor constituencies. Yet the patterns that machine learning exploits in Bitcoin volatility do not appear to exist in Ethereum, or perhaps exist in a form that these methods cannot capture effectively.

One potential explanation relates to market microstructure. Bitcoin, as the largest cryptocurrency, might exhibit more systematic trading patterns amenable to machine learning approaches. Ethereum's volatility dynamics might be driven more by idiosyncratic factors (protocol upgrades, decentralised finance activity, network congestion) that do not produce consistent patterns. The significance of EGARCH's improvement over symmetric GARCH (p<0.05) suggests that asymmetric volatility responses are the dominant feature in Ethereum markets. This interpretation is tentative; the data here do not settle it.

\subsection{Traditional Assets: S\&P 500}

The S\&P 500 results tell a different story from the cryptocurrency assets. The only statistically significant improvement over GARCH comes from EGARCH (p<0.01), consistent with decades of evidence on equity volatility: negative returns raise subsequent volatility more than positive returns of equivalent magnitude, and symmetric GARCH cannot capture this. XGBoost achieves the lowest raw RMSE (0.1286 versus GARCH's 0.1392), but the Diebold-Mariano test does not confirm this as significant (p=0.45). LSTM performs worse than GARCH outright, with an RMSE of 0.1430 against GARCH's 0.1392.

The implication is that, for mature equity markets, getting the model structure right matters more than adding machine learning complexity. The leverage effect is well understood, and EGARCH captures it directly. Machine learning methods do not appear to exploit additional structure in the data beyond what the asymmetric specification already accounts for.

For practitioners, these results suggest that EGARCH, not neural networks, is the appropriate upgrade from basic GARCH for equity volatility forecasting.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Contents/Chapters/1_Main/figures/model_comparison.png}
    \caption{Model performance comparison across assets (RMSE, lower values indicate superior performance)}
    \label{fig:model_comparison}
\end{figure}

\section{Comparative Analysis}

\subsection{Cryptocurrency versus Traditional Markets}

Table \ref{tab:asset_class} presents average performance metrics by asset class. These aggregates, however, obscure important heterogeneity.

\begin{table}[htbp]
\centering
\caption{Average RMSE by Asset Class (excluding VIX)}
\label{tab:asset_class}
\begin{tabular}{lccccc}
\toprule
Asset Class & GARCH & EGARCH & RF & XGBoost & LSTM \\
\midrule
Crypto (BTC, ETH) & 0.2554 & 0.2538 & 0.2492 & 0.2570 & \textbf{0.2475} \\
Traditional (SPX) & 0.1392 & 0.1294 & 0.1362 & \textbf{0.1286} & 0.1430 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Note: Bold indicates lowest average RMSE for each asset class.
\end{tablenotes}
\end{table}

The cryptocurrency average shows LSTM performing marginally best, with RF close behind. This average, however, masks important heterogeneity: machine learning methods significantly outperform GARCH for Bitcoin but not for Ethereum. Aggregation at the asset-class level thus obscures rather than illuminates the key pattern.

This observation carries methodological implications. Studies that report average performance across cryptocurrency assets miss important within-class variation. Model selection needs to proceed at the level of individual assets rather than asset categories.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{Contents/Chapters/1_Main/figures/crypto_vs_traditional.png}
    \caption{Average model performance: Cryptocurrency versus traditional assets}
    \label{fig:crypto_vs_trad}
\end{figure}

\subsection{Model Complexity and Performance}

The relationship between model complexity and forecast accuracy does not follow a monotonic pattern. For Bitcoin, tree-based methods perform best, with LSTM also significantly outperforming GARCH. For Ethereum and VIX, simpler methods match or exceed the neural network. For the S\&P 500, the most complex model (LSTM) performs worst, and only EGARCH, which adds targeted asymmetry rather than general complexity, achieves a meaningful improvement. Complexity helps only when the data contain exploitable patterns of the right kind.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Contents/Chapters/1_Main/figures/feature_importance.png}
    \caption{Random Forest feature importance by asset}
    \label{fig:feature_importance}
\end{figure}

Figure \ref{fig:feature_importance} displays feature importance measures from the Random Forest models. Across all assets, lagged volatility measures dominate, with recent returns contributing to a lesser degree. This pattern is consistent with the well-documented persistence of volatility: historical volatility remains the most informative predictor of future volatility. The relative homogeneity of feature importance across assets suggests that the differential performance of LSTM likely arises from temporal pattern exploitation rather than differences in relevant information.

\section{Discussion}

\subsection{Research Questions}

The findings permit responses to the research questions posed in Chapter 1.

\textbf{RQ1: Do machine learning methods achieve statistically significant improvements over GARCH-family models for volatility forecasting in cryptocurrency markets?}

The answer is asset-dependent. For Bitcoin, all machine learning methods significantly outperform GARCH(1,1), with XGBoost achieving the lowest RMSE (0.1848). The improvement of approximately 11 per cent relative to GARCH is statistically significant and potentially economically meaningful. For Ethereum, no machine learning method significantly outperforms GARCH; EGARCH achieves the best performance. A categorical answer regarding cryptocurrency markets is not supported by the evidence.

\textbf{RQ2: Do any performance advantages observed in cryptocurrency markets extend to traditional equity markets?}

Not through machine learning. No ML method achieves a statistically significant improvement over GARCH for the S\&P 500. EGARCH does, and substantially so (p<0.01), by capturing the leverage effect that symmetric GARCH misses. LSTM performs worse than GARCH outright. The ML advantage observed in Bitcoin does not extend to equities; if anything, the equity results favour simpler, structurally motivated specifications.

\textbf{RQ3: Among machine learning approaches, do more complex architectures such as LSTM provide meaningful improvements over simpler ensemble methods?}

The answer varies by asset. For Bitcoin, tree-based methods achieve lower RMSE than LSTM, though all three ML approaches significantly outperform GARCH. For Ethereum and VIX, LSTM offers no significant improvement over simpler methods. For the S\&P 500, LSTM is the worst-performing model. Across assets, greater complexity does not translate to better forecasts; in equities, it actively hurts.

\subsection{Implications for Practice}

A few observations for practitioners:

\begin{enumerate}
    \item \textbf{Asset-specific validation is essential}. The divergence between Bitcoin and Ethereum results demonstrates that performance within one asset does not predict performance in another, even within the same asset class. Model selection should proceed through asset-by-asset testing rather than categorical assumptions.

    \item \textbf{Statistical significance testing provides essential information}. Some apparent RMSE differences do not survive formal testing. Reliance on point estimates alone risks adopting methods that offer no genuine improvement.
\end{enumerate}

For equity markets, EGARCH is the appropriate upgrade: it captures the leverage effect directly, and machine learning methods including LSTM do not improve on it. LSTM performs worse than GARCH outright for the S\&P 500, and the computational investment in neural network implementation is not justified for this asset class. In crypto, LSTM does add value, but only for Bitcoin. Deployment should follow per-asset validation, not categorical assumptions about where neural networks help.

\subsection{Economic Significance}

Statistical significance does not automatically establish economic significance. The 11 per cent RMSE improvement for Bitcoin is statistically confirmed and could affect risk management decisions and position sizing for cryptocurrency portfolios. For equities, EGARCH's statistically significant improvement over GARCH could affect Value-at-Risk calculations, though the magnitude is modest and the practical effect unquantified here. Whether any of these improvements translate to realised gains in risk-adjusted returns remains an empirical question that the present analysis does not address directly.

\section{VIX: A Special Case}

\subsection{Distinctive Properties}

The VIX differs fundamentally from the other assets examined. Whilst Bitcoin, Ethereum, and the S\&P 500 are price-based instruments whose volatility is derived from return calculations, VIX already represents a volatility measure: specifically, the 30-day implied volatility of S\&P 500 options as calculated from options prices. Forecasting VIX volatility therefore involves predicting the volatility of volatility, a second-order quantity with distinct statistical properties.

VIX exhibits several characteristics relevant to forecasting:
\begin{itemize}
    \item Mean reversion towards a long-run average of approximately 20.
    \item Asymmetric dynamics: rapid increases during periods of market stress followed by gradual declines.
    \item Strong negative correlation with S\&P 500 returns (Figure \ref{fig:vix_analysis}).
    \item Bounded behaviour: practical floors and ceilings constrain the range of outcomes.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Contents/Chapters/1_Main/figures/vix_analysis.png}
    \caption{VIX characteristics (2019--2025)}
    \label{fig:vix_analysis}
\end{figure}

\subsection{Interpretation of Results}

Given these distinctive properties, the VIX results warrant separate consideration. Random Forest achieves the lowest RMSE (0.7916) and significantly outperforms GARCH(1,1). EGARCH also demonstrates significant improvement. LSTM, however, shows no significant difference from GARCH.

The elevated RMSE values across all methods (ranging from 0.79 to 0.98) reflect the inherent difficulty of forecasting volatility-of-volatility. The finding that tree-based methods outperform sequence models likely relates to the bounded, mean-reverting nature of VIX, which differs from the dynamics of return-based volatility.

\section{Robustness Considerations}

\subsection{Training Methodology}

One asymmetry in the experimental design deserves attention. GARCH models were re-estimated at each forecasting step, incorporating all available data up to the forecast origin. Machine learning models, by contrast, were trained once on the initial training set and subsequently held fixed. This approach reflects typical deployment practice (rolling neural network re-estimation would entail substantial computational cost) but confers an adaptability advantage to econometric methods.

The finding that EGARCH outperforms machine learning for the S\&P 500 might partly reflect this asymmetry. Whether periodic machine learning retraining would alter the conclusions is a question for future investigation.

\subsection{Additional Considerations}

A few additional factors affect generalisability:

\begin{enumerate}
    \item \textbf{Hyperparameter selection}: The machine learning models employ relatively standard configurations. Alternative hyperparameter choices might yield different results.
    \item \textbf{Sample period}: The 2019--2025 period encompasses the COVID-19 market disruption and multiple cryptocurrency market cycles. Performance in other periods may differ.
    \item \textbf{Neural network architecture}: More sophisticated designs, such as attention mechanisms or Transformer architectures, remain untested.
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Contents/Chapters/1_Main/figures/forecast_vs_actual.png}
    \caption{Best model forecasts versus realised volatility (final 100 observations)}
    \label{fig:forecast_actual}
\end{figure}
