\chapter{Limitations and Future Work}

No study covers everything. This chapter identifies the main constraints of the present analysis and points to where future work might pick up.

\section{Methodological Limitations}

\subsection{Neural Network Architecture}

The LSTM specification employed in this study (two layers of 64 and 32 units, with a 30-day lookback window) represents one of numerous possible configurations. More sophisticated architectures might yield different results. Attention mechanisms, which permit the network to focus selectively on informative time steps, could improve performance. Transformer architectures, which have achieved considerable success in natural language processing and other sequence modelling domains, represent another avenue that remains unexplored.

Whether more sophisticated architectures would change the core findings is unclear. LSTM performs well for Bitcoin but poorly for the S\&P 500 and Ethereum, suggesting the divergence reflects data characteristics rather than architectural limitations alone.

\subsection{Training Asymmetry}

GARCH models were re-estimated at each forecasting step, incorporating all available data up to the forecast origin. Machine learning models, by contrast, were trained once on the initial training set and subsequently held fixed. This asymmetry reflects typical deployment practice (the computational cost of daily neural network retraining would be substantial) but it gives econometric models more capacity to adapt to recent market developments.

The question of whether periodic machine learning retraining would alter the comparative findings is worth investigating, particularly for Bitcoin where ML methods show a consistent advantage. Rolling machine learning estimation would entail considerable computational expense but would permit a more balanced comparison.

\subsection{Forecast Horizon}

The analysis focuses exclusively on 5-day ahead volatility forecasts. This horizon is commonly employed in the literature but is not the only one of practical interest. Shorter horizons (next-day forecasts) or longer ones (monthly forecasts) might favour different models.

LSTM's capacity to capture extended temporal dependencies might prove more advantageous at longer forecast horizons, where GARCH's exponential decay of past information becomes more constraining. Conversely, shorter horizons might favour simpler specifications that adapt more rapidly to recent observations.

\subsection{Hyperparameter Configuration}

The machine learning models were deployed with standard, off-the-shelf configurations rather than extensively tuned hyperparameters. This was a deliberate choice: the goal was to assess how well these models perform in a realistic setting where a practitioner applies reasonable defaults. However, systematic hyperparameter optimisation (grid search, Bayesian optimisation, or similar) could alter the relative rankings. A well-tuned LSTM or XGBoost model might close the gap with GARCH in cases where it currently falls short, or widen it where ML already leads.

\subsection{Feature Specification}

The machine learning models employed only price-based features: lagged returns and realised volatility at various window lengths. This specification maintains comparability with GARCH, which also uses only price information, but likely limits machine learning performance.

For cryptocurrency assets, on-chain metrics (transaction volume, active addresses, exchange flows) might carry predictive information that prices alone do not capture. Sentiment indicators derived from social media or news sources could provide additional signals. Options-implied volatility, where available, represents market expectations that might prove useful as features. None of these alternative information sources were incorporated in the present analysis.

\subsection{Sample Period}

The data span from 2019 through 2025, a period that includes the COVID-19 market disruption and recovery, multiple cryptocurrency boom-bust cycles, and several episodes of unusual market behaviour. Whether the findings generalise to calmer or more turbulent periods remains an open question.

The marked divergence between Bitcoin and Ethereum results might be period-specific, reflecting particular market conditions during the sample. Alternatively, it might reflect persistent differences in how these assets trade. Testing on additional sample periods would help distinguish between these interpretations.

\section{Conceptual Limitations}

\subsection{VIX Interpretation}

The VIX differs fundamentally from the other assets examined. It already represents a volatility measure (specifically, the 30-day implied volatility of S\&P 500 options) rather than a price from which volatility is derived. Forecasting VIX volatility therefore involves predicting the volatility of volatility, a second-order quantity with distinct statistical properties.

The VIX results should be interpreted with this distinction in mind. Direct comparison with the price-based assets may not be entirely appropriate, and the findings for VIX might not generalise to other applications.

\subsection{Economic Significance}

This thesis focuses on statistical metrics: RMSE, MAE, and Diebold-Mariano test statistics. These measures are informative but do not directly address economic significance. The ultimate question of practical interest is whether improved forecasts translate to improved decisions: more accurate option pricing, tighter risk bounds, superior trading performance.

The 11 per cent RMSE improvement for Bitcoin is statistically significant, but whether it produces economically meaningful benefits remains unexamined. Backtesting of actual strategies, whilst beyond the scope of the present work, would be required to establish practical value.

\section{Directions for Future Research}

\subsection{Advanced Neural Network Architectures}

The most obvious next step is testing more sophisticated neural network designs. Transformer architectures, which have shown strong performance for sequence modelling in other domains, are a reasonable first candidate. Attention mechanisms could help models focus on the most informative historical observations. Whether such approaches would improve performance for assets where LSTM currently offers no advantage is a natural empirical question.

\subsection{Rolling Machine Learning Estimation}

Implementing periodic retraining of machine learning models would address the training asymmetry noted above. Models could be updated at monthly or quarterly intervals, balancing adaptation to recent market conditions against computational cost. This approach would permit a more balanced comparison with rolling GARCH estimation.

\subsection{Higher-Frequency Data}

Intraday data might favour sequence models such as LSTM more consistently. With substantially more observations per trading day (390 per day at one-minute frequency rather than one per day), the temporal structure available to the models would be considerably richer. Patterns that are obscured at daily frequency might become exploitable at higher resolution.

The tradeoffs involve data quality and computational requirements. Tick-level data can be noisy, and training on millions of observations requires careful implementation and substantial computing resources.

\subsection{Hybrid Models}

Combining econometric and machine learning approaches represents an appealing direction. One approach would use GARCH forecasts as features for machine learning models, permitting the network to learn when econometric predictions are likely to be biased. Another would feed GARCH residuals into an LSTM, allowing the network to capture any remaining structure not explained by the econometric specification.

Such hybrids might combine the interpretability of GARCH with the flexibility of machine learning, potentially achieving improvements over either approach in isolation.

\subsection{Additional Assets}

The four assets examined in this study are not exhaustive. Other cryptocurrencies (such as Solana, Cardano, or stablecoins), other equity indices (FTSE 100, DAX, Nikkei 225), commodities (gold, oil), and fixed income instruments would all warrant testing. The strong ML performance for Bitcoin but not for Ethereum suggests that asset-specific effects are substantial; examination of additional assets would help characterise the conditions under which machine learning approaches are likely to provide benefits.

\subsection{Economic Evaluation}

The most valuable extension would translate forecasting improvements into economic terms. This would involve backtesting trading strategies, evaluating option pricing accuracy, or assessing risk management performance. If an 11 per cent RMSE reduction for Bitcoin does not improve realised returns or risk-adjusted performance, the practical significance of the improvement might be limited.

Such evaluation would connect the statistical findings here to what actually motivates volatility forecasting: making better decisions.
